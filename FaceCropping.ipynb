{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceCropping.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b3_kAbR8nYv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "!bunzip2 \"shape_predictor_68_face_landmarks.dat.bz2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoVO1vJp81Kb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "predictor_path = 'shape_predictor_68_face_landmarks.dat'  # path of data\n",
        "\n",
        "#initializes dlibâ€™s pre-trained face detector based on a modification to the standard Histogram of Oriented Gradients + Linear SVM method for object detection.\n",
        "detector = dlib.get_frontal_face_detector() \n",
        "#loads the facial landmark predictor using the path\n",
        "predictor = dlib.shape_predictor(predictor_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNp8YVpi9VJt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# take a bounding predicted by dlib and convert it\n",
        "def rect_to_bb(rect):\n",
        "\t\n",
        "\t# to the format (x, y, w, h) as we would normally do\n",
        "\t# with OpenCV\n",
        "\tx1 = rect.left()\n",
        "\ty1 = rect.top()\n",
        "\tw1 = rect.right() - x1\n",
        "\th1 = rect.bottom() - y1\n",
        "\n",
        "\t# return a tuple of (x, y, w, h)\n",
        "\treturn (x1, y1, w1, h1)\n",
        " \n",
        "# extract 68 coordinate from shape object \n",
        "def shape_to_np(shape, dtype = int):\n",
        "  \n",
        "  coords = np.zeros((68, 2), dtype=dtype)\n",
        "  for i in range(0,68):\n",
        "    coords[i] = (shape.part(i).x, shape.part(i).y)\n",
        "  return coords # loop over the 68 facial landmarks and convert them\n",
        "\n",
        "# calculate forehead distance to use in cropping image\n",
        "def forehead_dist(coords):\n",
        "\n",
        "  d = (np.sum(coords[42:47,1]) - np.sum(coords[36:41,1]))/ 6\n",
        "  return d\n",
        "\n",
        "# calculate angle using eye landmark points i.e 42 to 47 is right eye and 36 to 41 is left eye \n",
        "def required_angle(shape):\n",
        "\t\n",
        "  val = (np.sum(shape[42:47,1]) - np.sum(shape[36:41,1]))/(np.sum(shape[42:47,0]) - np.sum(shape[36:41,0])) \n",
        "  angle = math.degrees(math.atan(val))\n",
        "  return angle\n",
        "\n",
        "#finally rotate image obtained by required_angle function\n",
        "def rotate_image(image, shape):\n",
        "  \n",
        "  angle = required_angle(shape)\n",
        "  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "  rotated_image = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "  return rotated_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-1_u-AH9aHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def face_cropping_without_forehead(image):             # implementing face cropping without forehead\n",
        "  gray_image = image\n",
        "  #gray_image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)  # convert color image to grayscale image\n",
        "  rects = detector(gray_image ,1)             # detect faces in the grayscale image\n",
        "  if len(rects) > 0:\n",
        "    images = []\n",
        "    for (i, rect) in enumerate(rects):\n",
        "\t\n",
        "      shape = predictor(image, rect)\n",
        "      shape = shape_to_np(shape)\n",
        "    \n",
        "      # convert dlib's rectangle to a OpenCV-style bounding box\n",
        "      # [i.e., (x, y, w, h)], then draw the face bounding box\n",
        "      (x1, y1, w1, h1) = rect_to_bb(rect)\n",
        "\n",
        "      d = forehead_dist(shape)\n",
        "      top_y = int(np.sum(shape[42 : 47, 1]) / 6 - 0.6 * d)\n",
        "      left_x, left_y = shape[0]\n",
        "      bottom_x, bottom_y = shape[8]\n",
        "      right_x, right_y = shape[16]\n",
        "      cropped_image = image[top_y : bottom_y, left_x : right_x]\n",
        "      if cropped_image.shape[0] == 0: \n",
        "        cropped_image = image[0:-1,left_x : right_x] \n",
        "      if cropped_image.shape[1] == 0:\n",
        "        cropped_image = image[top_y : bottom_y,  0:-1]\n",
        "      images.append(cropped_image)\n",
        "    if len(rects) == 1 :\n",
        "      return cropped_image\n",
        "    else:\n",
        "      return images\n",
        "\n",
        "  \n",
        "  else:\n",
        "    #print(\"Error : number of detected face is zero, so we just return original image\")\n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjIVlI_79eYB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def face_cropping_without_background(image):         # implementing face cropping without background\n",
        "  gray_image=image\n",
        "  #gray_image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)  # convert color image to grayscale image\n",
        "  rects = detector(gray_image ,1)             # detect faces in the grayscale image\n",
        "  if len(rects) > 0:\n",
        "    images = []\n",
        "    for (i, rect) in enumerate(rects):\n",
        "\t\n",
        "      shape = predictor(image, rect)\n",
        "      shape = shape_to_np(shape)\n",
        "    \n",
        "      # convert dlib's rectangle to a OpenCV-style bounding box\n",
        "      # [i.e., (x, y, w, h)], then draw the face bounding box\n",
        "      (x1, y1, w1, h1) = rect_to_bb(rect)\n",
        "\n",
        "      top_x, top_y = shape[19]\n",
        "      left_x, left_y = shape[0]\n",
        "      bottom_x, bottom_y = shape[8]\n",
        "      right_x, right_y = shape[16]\n",
        "      cropped_image = image[ min(top_y, abs(y1)) : max(bottom_y, abs(y1) + w1), min(left_x, abs(x1)) : max(right_x, abs(x1) + w1)]\n",
        "      if cropped_image.shape[0] == 0: \n",
        "        cropped_image = image[:,min(left_x, abs(x1)) : max(right_x, abs(x1) + w1)] \n",
        "      if cropped_image.shape[1] == 0:\n",
        "        cropped_image = image[min(top_y, abs(y1)) : max(bottom_y, abs(y1) + w1), :]\n",
        "      images.append(cropped_image)\n",
        "    if len(rects) == 1 :\n",
        "      return cropped_image\n",
        "    else:\n",
        "      return images\n",
        "  else:\n",
        "    print(\"Error : number of detected face is zero, so we just return original image\")\n",
        "    return image\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
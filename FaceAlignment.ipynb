{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceAlignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b3_kAbR8nYv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "!bunzip2 \"shape_predictor_68_face_landmarks.dat.bz2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoVO1vJp81Kb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "predictor_path = 'shape_predictor_68_face_landmarks.dat'  # path of data\n",
        "\n",
        "#initializes dlibâ€™s pre-trained face detector based on a modification to the standard Histogram of Oriented Gradients + Linear SVM method for object detection.\n",
        "detector = dlib.get_frontal_face_detector() \n",
        "#loads the facial landmark predictor using the path\n",
        "predictor = dlib.shape_predictor(predictor_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jY6w2Mm89YZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# take a bounding predicted by dlib and convert it\n",
        "def rect_to_bb(rect):\n",
        "\t\n",
        "\t# to the format (x, y, w, h) as we would normally do\n",
        "\t# with OpenCV\n",
        "\tx1 = rect.left()\n",
        "\ty1 = rect.top()\n",
        "\tw1 = rect.right() - x1\n",
        "\th1 = rect.bottom() - y1\n",
        "\n",
        "\t# return a tuple of (x, y, w, h)\n",
        "\treturn (x1, y1, w1, h1)\n",
        " \n",
        "# extract 68 coordinate from shape object \n",
        "def shape_to_np(shape, dtype = int):\n",
        "  \n",
        "  coords = np.zeros((68, 2), dtype=dtype)\n",
        "  for i in range(0,68):\n",
        "    coords[i] = (shape.part(i).x, shape.part(i).y)\n",
        "  return coords # loop over the 68 facial landmarks and convert them\n",
        "\n",
        "# calculate forehead distance to use in cropping image\n",
        "def forehead_dist(coords):\n",
        "\n",
        "  d = (np.sum(coords[42:47,1]) - np.sum(coords[36:41,1]))/ 6\n",
        "  return d\n",
        "\n",
        "# calculate angle using eye landmark points i.e 42 to 47 is right eye and 36 to 41 is left eye \n",
        "def required_angle(shape):\n",
        "\t\n",
        "  val = (np.sum(shape[42:47,1]) - np.sum(shape[36:41,1]))/(np.sum(shape[42:47,0]) - np.sum(shape[36:41,0])) \n",
        "  angle = math.degrees(math.atan(val))\n",
        "  return angle\n",
        "\n",
        "#finally rotate image obtained by required_angle function\n",
        "def rotate_image(image, shape):\n",
        "  \n",
        "  angle = required_angle(shape)\n",
        "  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "  rotated_image = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "  return rotated_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvjNZwUf8-XR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def face_alignment(image):             # implementing face alignment\n",
        "  image = np.array(image)\n",
        "  image = image.astype(np.uint8)\n",
        "  gray_image = image\n",
        "  #gray_image = cv2.cvtColor(image ,cv2.COLOR_BGR2GRAY) # convert color image to grayscale image\n",
        "  rects = detector(gray_image ,1)             # detect faces in the grayscale image\n",
        "  if len(rects) > 0:\n",
        "\n",
        "    images = []\n",
        "    for (i, rect) in enumerate(rects):\n",
        "      shape = predictor(image, rect)\n",
        "      shape = shape_to_np(shape)\n",
        "\n",
        "      rotated_image = rotate_image(image , shape)\n",
        "      images.append(rotated_image)\n",
        "    if len(rects) == 1 :\n",
        "      return rotated_image\n",
        "    else:\n",
        "      return images\n",
        "  else:\n",
        "    #print(\"Error : number of detected face is zero, so we just return original image\")\n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}